{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSI Mean Reversion Strategy - Backtesting Analysis\n",
    "\n",
    "This notebook demonstrates how to backtest the RSI Mean Reversion trading strategy on historical forex data.\n",
    "\n",
    "## Strategy Overview\n",
    "\n",
    "The RSI Mean Reversion strategy identifies oversold/overbought conditions and trades mean reversion opportunities.\n",
    "\n",
    "### Entry Rules\n",
    "- **LONG**: H1 price > EMA(200) AND M15 price touches lower BB AND RSI < 20\n",
    "- **SHORT**: H1 price < EMA(200) AND M15 price touches upper BB AND RSI > 80\n",
    "\n",
    "### Exit Rules\n",
    "- **Stop Loss**: Beyond BB extreme (1.1× BB distance)\n",
    "- **Take Profit**: 2× stop loss distance (1:2 R:R)\n",
    "\n",
    "### Expected Performance\n",
    "- Win Rate: 55-65%\n",
    "- Risk/Reward: 1:2\n",
    "- Trades per day: 2-4\n",
    "- Best pairs: EUR_USD, GBP_USD\n",
    "\n",
    "### Files\n",
    "- Strategy implementation: `src/strategies/rsi_mean_reversion.py`\n",
    "- Backtest script: `src/backtest_rsi.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from backtesting import Backtest\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Import strategy classes\n",
    "from src.strategies.rsi_mean_reversion import RSIMeanReversion, RSIMeanReversionOptimized, RSIMeanReversionMTF\n",
    "\n",
    "# Import data fetching classes (for auto-download)\n",
    "from src.oanda_client import OandaClient\n",
    "from src.data_retriever import HistoricalDataRetriever\n",
    "from src.data_storage import DataStorage\n",
    "\n",
    "# Import pandas_ta for H1 EMA calculation\n",
    "import pandas_ta as ta\n",
    "\n",
    "# Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Set the parameters for our backtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "INSTRUMENT = 'EUR_USD'\n",
    "GRANULARITY_ENTRY = 'M15'  # Entry signals timeframe\n",
    "GRANULARITY_TREND = 'H1'   # Trend filter timeframe\n",
    "FROM_DATE = '20250101'\n",
    "TO_DATE = '20251231'\n",
    "\n",
    "# Backtest parameters\n",
    "INITIAL_CASH = 10000\n",
    "COMMISSION = 0.0001  # 1 pip for forex\n",
    "\n",
    "# File paths\n",
    "DATA_DIR = Path('../data/historical')\n",
    "DATA_PATH_M15 = DATA_DIR / INSTRUMENT / f'{INSTRUMENT}_{GRANULARITY_ENTRY}_{FROM_DATE}_{TO_DATE}.csv'\n",
    "DATA_PATH_H1 = DATA_DIR / INSTRUMENT / f'{INSTRUMENT}_{GRANULARITY_TREND}_{FROM_DATE}_{TO_DATE}.csv'\n",
    "\n",
    "# API configuration path\n",
    "CONFIG_PATH = Path('../config/oanda_config.ini')\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Instrument: {INSTRUMENT}\")\n",
    "print(f\"  Entry Timeframe: {GRANULARITY_ENTRY} (RSI, Bollinger Bands)\")\n",
    "print(f\"  Trend Timeframe: {GRANULARITY_TREND} (EMA200 trend filter)\")\n",
    "print(f\"  Period: {FROM_DATE} to {TO_DATE}\")\n",
    "print(f\"  Initial Capital: ${INITIAL_CASH:,.2f}\")\n",
    "print(f\"  Commission: {COMMISSION*100:.2f}%\")\n",
    "print(f\"  M15 Data Path: {DATA_PATH_M15}\")\n",
    "print(f\"  M15 Data Exists: {DATA_PATH_M15.exists()}\")\n",
    "print(f\"  H1 Data Path: {DATA_PATH_H1}\")\n",
    "print(f\"  H1 Data Exists: {DATA_PATH_H1.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Historical Data\n",
    "\n",
    "Load both M15 (entry signals) and H1 (trend filter) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_data(instrument: str, granularity: str, from_date: str, to_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetch historical data from OANDA API and save to CSV.\n",
    "\n",
    "    Args:\n",
    "        instrument: Currency pair (e.g., 'EUR_USD')\n",
    "        granularity: Timeframe (e.g., 'M15')\n",
    "        from_date: Start date in YYYYMMDD format\n",
    "        to_date: End date in YYYYMMDD format\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with OHLCV data\n",
    "    \"\"\"\n",
    "    print(f\"Fetching {instrument} {granularity} data from OANDA API...\")\n",
    "    print(f\"Date range: {from_date} to {to_date}\")\n",
    "\n",
    "    # Convert YYYYMMDD to YYYY-MM-DD for API\n",
    "    from_date_api = f\"{from_date[:4]}-{from_date[4:6]}-{from_date[6:8]}\"\n",
    "    to_date_api = f\"{to_date[:4]}-{to_date[4:6]}-{to_date[6:8]}\"\n",
    "\n",
    "    # Initialize OANDA client\n",
    "    client = OandaClient(environment='practice', config_path=str(CONFIG_PATH))\n",
    "    print(\"✓ OANDA client initialized\")\n",
    "\n",
    "    # Initialize data retriever\n",
    "    retriever = HistoricalDataRetriever(client)\n",
    "\n",
    "    # Fetch data\n",
    "    df = retriever.fetch_historical_data(\n",
    "        instrument=instrument,\n",
    "        granularity=granularity,\n",
    "        from_date=from_date_api,\n",
    "        to_date=to_date_api\n",
    "    )\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data retrieved for {instrument}\")\n",
    "\n",
    "    print(f\"✓ Retrieved {len(df):,} candles\")\n",
    "\n",
    "    # Save to CSV\n",
    "    storage = DataStorage(base_path=str(DATA_DIR))\n",
    "    file_path = storage.save_to_csv(\n",
    "        df=df,\n",
    "        instrument=instrument,\n",
    "        granularity=granularity,\n",
    "        from_date=from_date_api,\n",
    "        to_date=to_date_api\n",
    "    )\n",
    "    print(f\"✓ Saved to: {file_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_data(data_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data from CSV file.\n",
    "\n",
    "    Args:\n",
    "        data_path: Path to CSV file\n",
    "\n",
    "    Returns:\n",
    "        DataFrame formatted for backtesting.py\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from: {data_path}\")\n",
    "\n",
    "    # Read CSV, skipping header comments (lines starting with #)\n",
    "    df = pd.read_csv(data_path, comment='#', parse_dates=['time'], index_col='time')\n",
    "\n",
    "    # Rename columns to match backtesting.py expectations (capitalized)\n",
    "    df.columns = [col.capitalize() for col in df.columns]\n",
    "\n",
    "    # Keep only required columns\n",
    "    required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    df = df[[col for col in required_cols if col in df.columns]]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def ensure_data_exists(data_path: Path, instrument: str, granularity: str, from_date: str, to_date: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure data exists, fetch if missing.\n",
    "\n",
    "    Args:\n",
    "        data_path: Path where data should be\n",
    "        instrument: Currency pair\n",
    "        granularity: Timeframe\n",
    "        from_date: Start date (YYYYMMDD)\n",
    "        to_date: End date (YYYYMMDD)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with OHLCV data\n",
    "    \"\"\"\n",
    "    if data_path.exists():\n",
    "        print(f\"✓ Data file found: {data_path}\")\n",
    "        return load_data(data_path)\n",
    "    else:\n",
    "        print(f\"✗ Data file not found: {data_path}\")\n",
    "        print(f\"  Downloading from OANDA API...\")\n",
    "        print()\n",
    "        fetch_and_save_data(instrument, granularity, from_date, to_date)\n",
    "        return load_data(data_path)\n",
    "\n",
    "\n",
    "# Main data loading logic\n",
    "print(\"=\" * 60)\n",
    "print(\"LOADING HISTORICAL DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load M15 data (entry signals)\n",
    "print(\"\\n[1/2] Loading M15 data (entry signals)...\")\n",
    "df_m15 = ensure_data_exists(DATA_PATH_M15, INSTRUMENT, GRANULARITY_ENTRY, FROM_DATE, TO_DATE)\n",
    "print(f\"✓ Loaded {len(df_m15):,} M15 candles\")\n",
    "print(f\"  Date range: {df_m15.index.min()} to {df_m15.index.max()}\")\n",
    "\n",
    "# Load H1 data (trend filter)\n",
    "print(\"\\n[2/2] Loading H1 data (trend filter)...\")\n",
    "df_h1 = ensure_data_exists(DATA_PATH_H1, INSTRUMENT, GRANULARITY_TREND, FROM_DATE, TO_DATE)\n",
    "print(f\"✓ Loaded {len(df_h1):,} H1 candles\")\n",
    "print(f\"  Date range: {df_h1.index.min()} to {df_h1.index.max()}\")\n",
    "\n",
    "# Set M15 as primary dataframe\n",
    "df = df_m15.copy()\n",
    "\n",
    "print(f\"\\n✓ Primary dataframe: M15 with {len(df):,} candles\")\n",
    "print(f\"  Duration: {(df.index.max() - df.index.min()).days} days\")\n",
    "print(f\"\\nM15 Data sample:\")\n",
    "display(df.head())\n",
    "print(\"\\nM15 Price statistics:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate H1 EMA200 and Merge to M15\n",
    "\n",
    "Calculate EMA200 on H1 data, then forward-fill to M15 timeframe for multi-timeframe strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CALCULATING H1 EMA200 AND MERGING TO M15\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate EMA200 on H1 data\n",
    "print(\"\\nCalculating EMA200 on H1 data...\")\n",
    "df_h1['EMA200'] = ta.ema(df_h1['Close'], length=200)\n",
    "print(f\"✓ H1 EMA200 calculated\")\n",
    "print(f\"  First valid EMA200: {df_h1['EMA200'].first_valid_index()}\")\n",
    "print(f\"  Non-null EMA200 values: {df_h1['EMA200'].notna().sum()}/{len(df_h1)}\")\n",
    "\n",
    "# Forward-fill H1 EMA200 to M15 timeframe\n",
    "print(\"\\nMerging H1 EMA200 to M15 timeframe (forward-fill)...\")\n",
    "df['H1_EMA200'] = df_h1['EMA200'].reindex(df.index, method='ffill')\n",
    "print(f\"✓ H1_EMA200 merged to M15 dataframe\")\n",
    "print(f\"  Non-null H1_EMA200 values: {df['H1_EMA200'].notna().sum()}/{len(df)}\")\n",
    "print(f\"  Null H1_EMA200 values: {df['H1_EMA200'].isna().sum()} (expected at start due to 200-period warmup)\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nM15 dataframe with H1_EMA200:\")\n",
    "display(df[['Open', 'High', 'Low', 'Close', 'H1_EMA200']].head(20))\n",
    "\n",
    "# Verify forward-fill logic\n",
    "print(\"\\nVerification: H1 EMA values are forward-filled across M15 bars\")\n",
    "sample_h1_time = df_h1.index[210]  # Pick an H1 bar after warmup\n",
    "h1_ema_value = df_h1.loc[sample_h1_time, 'EMA200']\n",
    "print(f\"  H1 bar at {sample_h1_time}: EMA200 = {h1_ema_value:.5f}\")\n",
    "m15_bars_in_hour = df[(df.index >= sample_h1_time) & (df.index < sample_h1_time + pd.Timedelta(hours=1))]\n",
    "print(f\"  M15 bars in that hour ({len(m15_bars_in_hour)} bars):\")\n",
    "display(m15_bars_in_hour[['Close', 'H1_EMA200']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Frequency Diagnostic\n",
    "\n",
    "Analyze how often RSI conditions are met and estimate expected trade count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"RSI SIGNAL FREQUENCY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate RSI on M15\n",
    "rsi = ta.rsi(df['Close'], length=14)\n",
    "\n",
    "# Calculate Bollinger Bands on M15\n",
    "bb = ta.bbands(df['Close'], length=20, std=2.0, mamode='sma')\n",
    "bb_lower = bb[f'BBL_20_2.0_2.0']\n",
    "bb_upper = bb[f'BBU_20_2.0_2.0']\n",
    "\n",
    "# RSI distribution\n",
    "print(\"\\nRSI Distribution:\")\n",
    "print(f\"  RSI < 20: {(rsi < 20).sum():,} bars ({(rsi < 20).sum()/len(rsi)*100:.2f}%)\")\n",
    "print(f\"  RSI < 30: {(rsi < 30).sum():,} bars ({(rsi < 30).sum()/len(rsi)*100:.2f}%)\")\n",
    "print(f\"  RSI > 70: {(rsi > 70).sum():,} bars ({(rsi > 70).sum()/len(rsi)*100:.2f}%)\")\n",
    "print(f\"  RSI > 80: {(rsi > 80).sum():,} bars ({(rsi > 80).sum()/len(rsi)*100:.2f}%)\")\n",
    "\n",
    "# Signal frequency (approximate - doesn't account for position already open)\n",
    "print(\"\\nApproximate Signal Frequency (ignoring position filter):\")\n",
    "\n",
    "# Bollinger Band touches (1% tolerance)\n",
    "touches_lower_bb = df['Close'] <= bb_lower * 1.001\n",
    "touches_upper_bb = df['Close'] >= bb_upper * 0.999\n",
    "\n",
    "# Trend conditions (using H1_EMA200)\n",
    "ema_trend_up = df['Close'] > df['H1_EMA200']\n",
    "ema_trend_down = df['Close'] < df['H1_EMA200']\n",
    "\n",
    "# Combined signals with RSI 20/80 (original)\n",
    "long_signals_20 = ema_trend_up & touches_lower_bb & (rsi < 20)\n",
    "short_signals_20 = ema_trend_down & touches_upper_bb & (rsi > 80)\n",
    "total_signals_20 = long_signals_20.sum() + short_signals_20.sum()\n",
    "\n",
    "# Combined signals with RSI 30/70 (recommended)\n",
    "long_signals_30 = ema_trend_up & touches_lower_bb & (rsi < 30)\n",
    "short_signals_30 = ema_trend_down & touches_upper_bb & (rsi > 70)\n",
    "total_signals_30 = long_signals_30.sum() + short_signals_30.sum()\n",
    "\n",
    "print(f\"\\n  RSI 20/80 (original):\")\n",
    "print(f\"    LONG signals: {long_signals_20.sum():,}\")\n",
    "print(f\"    SHORT signals: {short_signals_20.sum():,}\")\n",
    "print(f\"    Total signals: {total_signals_20:,}\")\n",
    "print(f\"    Expected trades: {total_signals_20//3:,} (approximate, accounting for overlap)\")\n",
    "\n",
    "print(f\"\\n  RSI 30/70 (recommended):\")\n",
    "print(f\"    LONG signals: {long_signals_30.sum():,}\")\n",
    "print(f\"    SHORT signals: {short_signals_30.sum():,}\")\n",
    "print(f\"    Total signals: {total_signals_30:,}\")\n",
    "print(f\"    Expected trades: {total_signals_30//3:,} (approximate, accounting for overlap)\")\n",
    "\n",
    "print(f\"\\n  Signal increase with RSI 30/70: {total_signals_30/max(total_signals_20,1):.1f}x\")\n",
    "\n",
    "# Histogram\n",
    "print(\"\\nRSI Distribution Histogram:\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(rsi.dropna(), bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "plt.axvline(20, color='red', linestyle='--', linewidth=2, label='RSI 20')\n",
    "plt.axvline(30, color='orange', linestyle='--', linewidth=2, label='RSI 30')\n",
    "plt.axvline(70, color='orange', linestyle='--', linewidth=2, label='RSI 70')\n",
    "plt.axvline(80, color='red', linestyle='--', linewidth=2, label='RSI 80')\n",
    "plt.xlabel('RSI Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('RSI Distribution - M15 Timeframe')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create candlestick chart\n",
    "fig = go.Figure(data=[go.Candlestick(\n",
    "    x=df.index,\n",
    "    open=df['Open'],\n",
    "    high=df['High'],\n",
    "    low=df['Low'],\n",
    "    close=df['Close'],\n",
    "    name=INSTRUMENT\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f'{INSTRUMENT} {GRANULARITY_ENTRY} - {FROM_DATE[:4]}',\n",
    "    yaxis_title='Price',\n",
    "    xaxis_title='Date',\n",
    "    height=600,\n",
    "    xaxis_rangeslider_visible=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Basic Backtest (Multi-Timeframe Strategy)\n",
    "\n",
    "Run the multi-timeframe RSI Mean Reversion strategy (H1 trend + M15 entries) with RSI 30/70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize backtest with multi-timeframe strategy\n",
    "bt = Backtest(df, RSIMeanReversionMTF, cash=INITIAL_CASH, commission=COMMISSION)\n",
    "\n",
    "# Run backtest\n",
    "print(\"Running backtest with multi-timeframe strategy...\\n\")\n",
    "stats = bt.run()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BACKTEST RESULTS - MULTI-TIMEFRAME STRATEGY (H1 + M15)\")\n",
    "print(\"=\" * 80)\n",
    "print(stats)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Metrics Explanation\n",
    "\n",
    "- **Return [%]**: Total percentage return over the period\n",
    "- **Sharpe Ratio**: Risk-adjusted return (> 1.0 is good, > 2.0 is excellent)\n",
    "- **Max Drawdown [%]**: Largest peak-to-trough decline\n",
    "- **Win Rate [%]**: Percentage of profitable trades\n",
    "- **Profit Factor**: Gross profit / Gross loss (> 1.0 is profitable)\n",
    "- **Exposure Time [%]**: Percentage of time in position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Equity Curve Visualization\n",
    "\n",
    "Visualize the equity curve and drawdown periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract equity curve\n",
    "equity = stats['_equity_curve']\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.1,\n",
    "    subplot_titles=('Equity Curve', 'Drawdown'),\n",
    "    row_heights=[0.7, 0.3]\n",
    ")\n",
    "\n",
    "# Equity curve\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=equity.index, y=equity['Equity'], name='Equity', line=dict(color='blue', width=2)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add starting capital line\n",
    "fig.add_hline(y=INITIAL_CASH, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Initial Capital\", row=1, col=1)\n",
    "\n",
    "# Drawdown\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=equity.index, y=equity['DrawdownPct'], name='Drawdown',\n",
    "               fill='tozeroy', line=dict(color='red', width=1)),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Equity ($)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Drawdown (%)\", row=2, col=1)\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Strategy Performance - Multi-Timeframe RSI Mean Reversion (H1 + M15)\", showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trade Analysis\n",
    "\n",
    "Analyze individual trades and their characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trades\n",
    "trades = stats['_trades']\n",
    "\n",
    "if len(trades) > 0:\n",
    "    print(f\"Total Trades: {len(trades)}\")\n",
    "    print(f\"\\nTrade Summary:\")\n",
    "    display(trades)\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    winning_trades = trades[trades['PnL'] > 0]\n",
    "    losing_trades = trades[trades['PnL'] < 0]\n",
    "\n",
    "    print(f\"\\n=\" * 60)\n",
    "    print(\"TRADE BREAKDOWN\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Winning trades: {len(winning_trades)} ({len(winning_trades)/len(trades)*100:.1f}%)\")\n",
    "    print(f\"Losing trades: {len(losing_trades)} ({len(losing_trades)/len(trades)*100:.1f}%)\")\n",
    "    print(f\"\\nLong trades: {len(trades[trades['Size'] > 0])} ({len(trades[trades['Size'] > 0])/len(trades)*100:.1f}%)\")\n",
    "    print(f\"Short trades: {len(trades[trades['Size'] < 0])} ({len(trades[trades['Size'] < 0])/len(trades)*100:.1f}%)\")\n",
    "\n",
    "    if len(winning_trades) > 0:\n",
    "        print(f\"\\nAverage winning trade: ${winning_trades['PnL'].mean():.2f}\")\n",
    "        print(f\"Best trade: ${winning_trades['PnL'].max():.2f}\")\n",
    "\n",
    "    if len(losing_trades) > 0:\n",
    "        print(f\"\\nAverage losing trade: ${losing_trades['PnL'].mean():.2f}\")\n",
    "        print(f\"Worst trade: ${losing_trades['PnL'].min():.2f}\")\n",
    "else:\n",
    "    print(\"⚠️ No trades executed. Strategy conditions may be too strict.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(trades) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # Trade returns histogram\n",
    "    axes[0, 0].hist(trades['ReturnPct'] * 100, bins=20, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[0, 0].axvline(0, color='red', linestyle='--', linewidth=1)\n",
    "    axes[0, 0].set_xlabel('Return (%)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Trade Return Distribution')\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "    # Trade P&L histogram\n",
    "    axes[0, 1].hist(trades['PnL'], bins=20, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[0, 1].axvline(0, color='red', linestyle='--', linewidth=1)\n",
    "    axes[0, 1].set_xlabel('P&L ($)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Trade P&L Distribution')\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "    # Trade duration\n",
    "    durations = (trades['ExitTime'] - trades['EntryTime']).dt.total_seconds() / 3600  # hours\n",
    "    axes[1, 0].hist(durations, bins=20, edgecolor='black', alpha=0.7, color='orange')\n",
    "    axes[1, 0].set_xlabel('Duration (hours)')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Trade Duration Distribution')\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "    # Cumulative P&L\n",
    "    cumulative_pnl = trades['PnL'].cumsum()\n",
    "    axes[1, 1].plot(range(len(cumulative_pnl)), cumulative_pnl, linewidth=2, color='darkblue')\n",
    "    axes[1, 1].axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "    axes[1, 1].set_xlabel('Trade Number')\n",
    "    axes[1, 1].set_ylabel('Cumulative P&L ($)')\n",
    "    axes[1, 1].set_title('Cumulative Profit/Loss')\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️ No trades to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimized Strategy Comparison\n",
    "\n",
    "Compare the base strategy with the optimized variant that includes additional filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimized strategy\n",
    "bt_optimized = Backtest(df, RSIMeanReversionOptimized, cash=INITIAL_CASH, commission=COMMISSION)\n",
    "stats_optimized = bt_optimized.run()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BACKTEST RESULTS - OPTIMIZED STRATEGY\")\n",
    "print(\"=\" * 80)\n",
    "print(stats_optimized)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    'Base Strategy': [\n",
    "        f\"{stats['Return [%]']:.2f}%\",\n",
    "        f\"{stats['Sharpe Ratio']:.2f}\",\n",
    "        f\"{stats['Max. Drawdown [%]']:.2f}%\",\n",
    "        f\"{stats['Win Rate [%]']:.2f}%\",\n",
    "        int(stats['# Trades']),\n",
    "        f\"{stats['Exposure Time [%]']:.2f}%\",\n",
    "        f\"${stats['Equity Final [$]']:.2f}\"\n",
    "    ],\n",
    "    'Optimized Strategy': [\n",
    "        f\"{stats_optimized['Return [%]']:.2f}%\",\n",
    "        f\"{stats_optimized['Sharpe Ratio']:.2f}\",\n",
    "        f\"{stats_optimized['Max. Drawdown [%]']:.2f}%\",\n",
    "        f\"{stats_optimized['Win Rate [%]']:.2f}%\",\n",
    "        int(stats_optimized['# Trades']),\n",
    "        f\"{stats_optimized['Exposure Time [%]']:.2f}%\",\n",
    "        f\"${stats_optimized['Equity Final [$]']:.2f}\"\n",
    "    ]\n",
    "}, index=['Return', 'Sharpe Ratio', 'Max Drawdown', 'Win Rate', '# Trades', 'Exposure Time', 'Final Equity'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STRATEGY COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "display(comparison)\n",
    "\n",
    "# Overlay equity curves\n",
    "equity_base = stats['_equity_curve']\n",
    "equity_optimized = stats_optimized['_equity_curve']\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=equity_base.index, y=equity_base['Equity'], name='Base Strategy', line=dict(color='blue', width=2)))\n",
    "fig.add_trace(go.Scatter(x=equity_optimized.index, y=equity_optimized['Equity'], name='Optimized Strategy', line=dict(color='green', width=2)))\n",
    "fig.add_hline(y=INITIAL_CASH, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Initial Capital\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Strategy Comparison - Equity Curves',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Equity ($)',\n",
    "    height=600,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Parameter Optimization\n",
    "\n",
    "Find optimal parameter combinations through grid search optimization.\n",
    "\n",
    "**Note**: This may take 2-5 minutes depending on parameter ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running parameter optimization...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "# Define optimization ranges\n",
    "stats_opt = bt.optimize(\n",
    "    rsi_period=range(10, 21, 2),\n",
    "    rsi_oversold=range(15, 31, 5),\n",
    "    rsi_overbought=range(70, 86, 5),\n",
    "    bb_period=range(15, 26, 5),\n",
    "    maximize='Sharpe Ratio',\n",
    "    constraint=lambda p: p.rsi_oversold < 50 and p.rsi_overbought > 50,\n",
    "    return_heatmap=False\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"OPTIMIZATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(stats_opt)\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract optimal parameters\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OPTIMAL PARAMETERS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"RSI Period: {stats_opt._strategy.rsi_period}\")\n",
    "print(f\"RSI Oversold: {stats_opt._strategy.rsi_oversold}\")\n",
    "print(f\"RSI Overbought: {stats_opt._strategy.rsi_overbought}\")\n",
    "print(f\"BB Period: {stats_opt._strategy.bb_period}\")\n",
    "print(f\"BB Std Dev: {stats_opt._strategy.bb_std}\")\n",
    "print(f\"\\nOptimized Sharpe Ratio: {stats_opt['Sharpe Ratio']:.2f}\")\n",
    "print(f\"Optimized Return: {stats_opt['Return [%]']:.2f}%\")\n",
    "print(f\"Optimized Win Rate: {stats_opt['Win Rate [%]']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Strategy Performance**: The RSI Mean Reversion strategy shows [analyze results here]\n",
    "2. **Trade Frequency**: Strategy generates [number] trades over the year\n",
    "3. **Win Rate**: Actual win rate is [X]%, [compared to expected 55-65%]\n",
    "4. **Risk Management**: Max drawdown of [X]% shows [assessment]\n",
    "5. **Optimization**: Parameter optimization [improved/didn't improve] performance significantly\n",
    "\n",
    "### Strategy Strengths\n",
    "- Clear entry/exit rules based on technical indicators\n",
    "- Defined risk management with stop loss and take profit\n",
    "- Trend filter (EMA200) helps avoid counter-trend trades\n",
    "- Mean reversion edge in ranging markets\n",
    "\n",
    "### Strategy Weaknesses\n",
    "- May generate few signals if conditions are too strict\n",
    "- Sensitive to parameter selection\n",
    "- Performance depends on market regime (range-bound vs trending)\n",
    "- Requires sufficient volatility for mean reversion\n",
    "\n",
    "### Recommendations\n",
    "1. **Parameter Tuning**: Consider using optimized parameters for live trading\n",
    "2. **Walk-Forward Analysis**: Test on out-of-sample data to avoid overfitting\n",
    "3. **Market Regime Filter**: Add volatility filter to avoid low-volatility periods\n",
    "4. **Position Sizing**: Implement dynamic position sizing based on account equity\n",
    "5. **Risk Management**: Consider reducing risk_reward ratio if win rate is high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "Now that you've analyzed the strategy performance, here are suggested next steps:\n",
    "\n",
    "### 1. Test on Different Instruments\n",
    "- Retrieve data for GBP_USD, USD_JPY, AUD_USD\n",
    "- Run same backtest to see if strategy is instrument-specific\n",
    "- Compare performance across major pairs\n",
    "\n",
    "### 2. Walk-Forward Analysis\n",
    "- Split data into in-sample (training) and out-of-sample (testing)\n",
    "- Optimize on in-sample, validate on out-of-sample\n",
    "- Check for overfitting\n",
    "\n",
    "### 3. Different Timeframes\n",
    "- Test on H1 (1-hour) and H4 (4-hour) data\n",
    "- Compare trade frequency and performance\n",
    "- Find optimal timeframe for your trading style\n",
    "\n",
    "### 4. Add Position Sizing\n",
    "- Implement Kelly Criterion or fixed fractional position sizing\n",
    "- Risk 1-2% of capital per trade\n",
    "- See `src/utils/position_sizing.py` (to be created)\n",
    "\n",
    "### 5. Paper Trading\n",
    "- Test strategy on OANDA practice account\n",
    "- Monitor real-time performance\n",
    "- Adjust parameters based on live market conditions\n",
    "\n",
    "### 6. Create Trading Journal\n",
    "- Log all trades with entry/exit reasons\n",
    "- Track emotions and decision-making process\n",
    "- Review weekly/monthly to improve\n",
    "\n",
    "### 7. Strategy Enhancements\n",
    "- Add volatility filter (ATR, BB width)\n",
    "- Implement time-of-day filter (London/NY session)\n",
    "- Add news event filter\n",
    "- Consider machine learning for signal confirmation\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: Past performance does not guarantee future results. Always paper trade before going live!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading-strategies (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
